{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bir13iITj9a0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/brain_tumor'\n",
        "\n",
        "# Set the paths to train and test folders\n",
        "train_dir = os.path.join(dataset_path, 'train_set')\n",
        "test_dir = os.path.join(dataset_path, 'test_set')\n"
      ],
      "metadata": {
        "id": "zN46YJ0dkPRm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKfLwpxkkQOj",
        "outputId": "2e2031ef-3ae1-45fa-b412-ff61efb6361f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 219 images belonging to 2 classes.\n",
            "Found 37 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "uWS8oJfqkTFe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "Tk5eu_7pkWZY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator,\n",
        "          steps_per_epoch=train_generator.samples,\n",
        "          epochs=10,\n",
        "          validation_data=test_generator,\n",
        "          validation_steps=test_generator.samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu_BLZpYkZOQ",
        "outputId": "7892ad2f-9210-49cf-da25-d022ac2610e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 11/219 [>.............................] - ETA: 8:39 - loss: 0.5369 - accuracy: 0.7443"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2190 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 37 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r219/219 [==============================] - 48s 181ms/step - loss: 0.5369 - accuracy: 0.7443 - val_loss: 0.7144 - val_accuracy: 0.7297\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a48ec410df0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"braintumor.h5\")"
      ],
      "metadata": {
        "id": "SS6ltR0NkbZW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "mT4qadTnmgFr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=load_model('chat.h5')"
      ],
      "metadata": {
        "id": "D6weNJ4knQB2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=image.load_img(r\"/content/drive/MyDrive/brain_tumor/test_set/no/N22.JPG\",target_size=(64,64))\n",
        "img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "X1NjmsK8nX3K",
        "outputId": "95892f19-684d-4e9f-fe44-911440c67356"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=image.img_to_array(img)\n",
        "x=np.expand_dims(x,axis=0)\n",
        "def preprocess_image(image_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(150, 150))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Normalize the pixel values (similar to what we did during training)\n",
        "    return img_array\n",
        "x = preprocess_image(\"/content/drive/MyDrive/no/1 no.jpeg\")\n",
        "\n",
        "pred=model.predict(x)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_DOYuhxnmqA",
        "outputId": "562acbc7-da67-4f8e-a9f3-71da07651daa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 153ms/step\n",
            "[[0.16303137]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = load_model('chat.h5')\n",
        "\n",
        "# Now, you can use the loaded model to predict on new data\n",
        "# For example, if you have a new image that you want to test, you can preprocess it and make predictions as follows:\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(150, 150))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Normalize the pixel values (similar to what we did during training)\n",
        "    return img_array\n",
        "\n",
        "new_image_path = '/content/drive/MyDrive/no/2 no.jpeg'\n",
        "new_image = preprocess_image(new_image_path)\n",
        "\n",
        "# Use the loaded model to make predictions on the new image\n",
        "prediction = loaded_model.predict(new_image)\n",
        "\n",
        "# The 'prediction' variable now contains the model's prediction, which is a value close to 0 for 'no tumor' and close to 1 for 'tumor'\n",
        "# You can interpret the prediction based on the threshold (e.g., if prediction >= 0.5, it's predicted as 'tumor')\n",
        "if prediction >0.5:\n",
        "    print(\"The model predicts that the image has a brain tumor.\")\n",
        "else:\n",
        "    print(\"The model predicts that the image does not have a brain tumor.\")\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hqHluI1k5VD",
        "outputId": "90e2f5e1-7954-4018-eca0-f372433a31ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 96ms/step\n",
            "The model predicts that the image does not have a brain tumor.\n",
            "[[0.19921926]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from flask import Flask, request, render_template, redirect, url_for\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "app = Flask(__name__)\n",
        "app.config['UPLOAD_FOLDER'] = 'uploads'\n",
        "app.config['ALLOWED_EXTENSIONS'] = {'jpg', 'jpeg', 'png'}\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('chat.h5')\n",
        "\n",
        "# Helper function to check if the file has an allowed extension\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']\n",
        "\n",
        "# Route to handle the home page\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "# Route to handle the prediction\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if request.method == 'POST':\n",
        "        if 'file' not in request.files:\n",
        "            return redirect(request.url)\n",
        "\n",
        "        file = request.files['file']\n",
        "\n",
        "        if file.filename == '':\n",
        "            return redirect(request.url)\n",
        "\n",
        "        if file and allowed_file(file.filename):\n",
        "            # Save the uploaded file to the 'uploads' folder\n",
        "            filename = file.filename\n",
        "            file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
        "            file.save(file_path)\n",
        "\n",
        "            # Preprocess the image\n",
        "            img = load_img(file_path, target_size=(150, 150))\n",
        "            img_array = img_to_array(img)\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "            img_array /= 255.0\n",
        "\n",
        "            # Use the model to make predictions\n",
        "            prediction = model.predict(img_array)\n",
        "\n",
        "            # Interpret the prediction\n",
        "            if prediction >= 0.5:\n",
        "                result = 'Tumor detected'\n",
        "            else:\n",
        "                result = 'No tumor detected'\n",
        "\n",
        "            return render_template('result.html', filename=filename, result=result)\n",
        "        else:\n",
        "            return render_template('error.html', error='Invalid file format. Please upload an image (jpg, jpeg, or png).')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "id": "CRVdpui8os-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e9cc79-faf1-4a4b-8a68-7f7a93114b7d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    }
  ]
}